{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from internal.dataparsers.colmap_dataparser import ColmapDataParser\n",
    "import internal.utils.colmap as colmap_utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ],
   "id": "e928f302be93763f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.set_grad_enabled(False)\n",
    "torch.set_printoptions(precision=16)"
   ],
   "id": "691bf3dde3296bb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from internal.utils.partitioning_utils import SceneConfig, PartitionableScene",
   "id": "b9ca4c6a8ec2a1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "The dataset \"Rubble\" can be downloaded here: https://storage.cmusatyalab.org/mega-nerf-data/rubble-pixsfm.tgz\n",
    "Convert it to colmap format by: `python utils/meganerf2colmap.py ~/data/Mega-NeRF/rubble-pixsfm`\n",
    "Down sample images by: `python utils/image_downsample.py ~/data/Mega-NeRF/rubble-pixsfm/colmap/images --factor 3`\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = os.path.expanduser(\"~/data/Mega-NeRF/rubble-pixsfm/colmap\")"
   ],
   "id": "12111ce0923c5c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Load dataset",
   "id": "deda9f038e3dfa08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colmap_model = colmap_utils.read_model(os.path.join(dataset_path, \"sparse\"))\n",
    "colmap_model = {\n",
    "    \"cameras\": colmap_model[0],\n",
    "    \"images\": colmap_model[1],\n",
    "    \"points3D\": colmap_model[2],\n",
    "}\n",
    "\n",
    "len(colmap_model[\"cameras\"]), len(colmap_model[\"images\"]), len(colmap_model[\"points3D\"])"
   ],
   "id": "5b213e5bcf1b8234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "get camera extrinsics",
   "id": "477bf65f12908096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "R_list = []\n",
    "T_list = []\n",
    "image_name_list = []\n",
    "image_idx_to_key = []\n",
    "\n",
    "for idx, key in enumerate(colmap_model[\"images\"]):\n",
    "    extrinsics = colmap_model[\"images\"][key]\n",
    "    image_name_list.append(extrinsics.name)\n",
    "\n",
    "    R = torch.tensor(extrinsics.qvec2rotmat(), dtype=torch.float)\n",
    "    T = torch.tensor(extrinsics.tvec, dtype=torch.float)\n",
    "\n",
    "    R_list.append(R)\n",
    "    T_list.append(T)\n",
    "    image_idx_to_key.append(key)\n",
    "\n",
    "R = torch.stack(R_list)\n",
    "T = torch.stack(T_list)\n",
    "\n",
    "assert image_idx_to_key[0] == list(colmap_model[\"images\"].keys())[0]\n",
    "assert image_idx_to_key[-1] == list(colmap_model[\"images\"].keys())[-1]\n",
    "\n",
    "R.shape, T.shape, len(image_idx_to_key),"
   ],
   "id": "59000629595448e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate camera-to-world transform matrix\n",
    "w2c = torch.zeros(size=(R.shape[0], 4, 4), dtype=R.dtype)\n",
    "w2c[:, :3, :3] = R\n",
    "w2c[:, :3, 3] = T\n",
    "w2c[:, 3, 3] = 1.\n",
    "c2w = torch.linalg.inv(w2c)"
   ],
   "id": "8deeff682b20aae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "get points",
   "id": "86191ef6f063706d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_point_index = max(colmap_model[\"points3D\"].keys())\n",
    "max_point_index"
   ],
   "id": "df4c7e78ae4e6713",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "point_xyzs = torch.zeros((max_point_index + 1, 3), dtype=torch.float)\n",
    "point_rgbs = torch.zeros((max_point_index + 1, 3), dtype=torch.uint8)\n",
    "point_errors = torch.ones((max_point_index + 1), dtype=torch.float).fill_(255.)\n",
    "point_n_images = torch.zeros((max_point_index + 1), dtype=torch.int)"
   ],
   "id": "d2b54fca39ee807c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, point in tqdm(colmap_model[\"points3D\"].items()):\n",
    "    point_xyzs[idx] = torch.from_numpy(point.xyz)\n",
    "    point_rgbs[idx] = torch.from_numpy(point.rgb)\n",
    "    point_errors[idx] = torch.from_numpy(point.error)\n",
    "    point_n_images[idx] = point.image_ids.shape[0]"
   ],
   "id": "e93a8d36abb9c468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "reorientation",
   "id": "c982e2ee3bc47bb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculate the up direction of the scene\n",
    "# NOTE: \n",
    "#   the calculated direction may not be perfect or even incorrect sometimes, \n",
    "#   in such a situation, you need to provide a correct up vector\n",
    "up = -torch.mean(c2w[:, :3, 1], dim=0)\n",
    "up = up / torch.linalg.norm(up)\n",
    "\n",
    "rotation = ColmapDataParser.rotation_matrix(up, torch.tensor([0, 0, 1], dtype=up.dtype))\n",
    "rotation_transform = torch.eye(4, dtype=up.dtype)\n",
    "rotation_transform[:3, :3] = rotation\n",
    "\n",
    "# an extra rotation aligning the camera paths to xy axis\n",
    "import numpy as np\n",
    "import viser.transforms as vt\n",
    "extra_rotation = torch.eye(4)\n",
    "extra_rotation[:3, :3] = torch.from_numpy(vt.SO3.from_z_radians(-np.pi / 8.5).as_matrix())\n",
    "rotation_transform = extra_rotation @ rotation_transform\n",
    "\n",
    "up, rotation_transform"
   ],
   "id": "3d29be537fd274b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reoriented_camera_centers = c2w[:, :3, 3] @ rotation_transform[:3, :3].T\n",
    "reoriented_point_cloud_xyz = point_xyzs @ rotation_transform[:3, :3].T"
   ],
   "id": "316ba52fdc03e9c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "extract valid points",
   "id": "d76fdff4474959ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "valid_point_mask = point_n_images > 0\n",
    "valid_reoriented_point_xyzs = reoriented_point_cloud_xyz[valid_point_mask]\n",
    "valid_point_rgbs = point_rgbs[valid_point_mask]\n",
    "len(valid_reoriented_point_xyzs), len(valid_point_rgbs)"
   ],
   "id": "62b76a56dc0a43df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "plot the scene, confirming that it shows in top view",
   "id": "a79ca4e9cf3784dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sparsify_points = 16\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "scene_size = torch.max(reoriented_camera_centers, dim=0).values - torch.min(reoriented_camera_centers, dim=0).values\n",
    "ax.set_xlim([torch.min(reoriented_camera_centers[:, 0]) - 0.1 * scene_size[0], torch.max(reoriented_camera_centers[:, 0]) + 0.1 * scene_size[0]])\n",
    "ax.set_ylim([torch.min(reoriented_camera_centers[:, 1]) - 0.1 * scene_size[1], torch.max(reoriented_camera_centers[:, 1]) + 0.1 * scene_size[1]])\n",
    "ax.scatter(valid_reoriented_point_xyzs[::sparsify_points, 0], valid_reoriented_point_xyzs[::sparsify_points, 1], c=valid_point_rgbs[::sparsify_points] / 255., s=0.01)\n",
    "ax.scatter(reoriented_camera_centers[:, 0], reoriented_camera_centers[:, 1], s=0.2, c=\"red\")\n",
    "plt.show()"
   ],
   "id": "7d049aabd88e0311",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Build partitions",
   "id": "712443556bd236c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "choose scene origin and partition size",
   "id": "9de32d9df7e286fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scene_config = SceneConfig(\n",
    "    origin=torch.tensor([0., -56.]),\n",
    "    partition_size=60.,\n",
    ")\n",
    "scene = PartitionableScene(scene_config, reoriented_camera_centers[..., :2])"
   ],
   "id": "11c758c560c684bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "calculate bounding box and number of partitions",
   "id": "5ced409320266c45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.get_bounding_box_by_camera_centers()",
   "id": "8e40f69c8cdf7d2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.get_scene_bounding_box()",
   "id": "d5770f7706582061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "plot bounding box",
   "id": "dc5b7a3ab989423"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.plot(scene.plot_scene_bounding_box)",
   "id": "be500202eb7c7e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "build partition coordinates",
   "id": "1aedb6aa364526c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.build_partition_coordinates()",
   "id": "6d082afbc1f0e692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "plot partitions",
   "id": "bb1a73e3dd9c1378"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.plot(scene.plot_partitions)",
   "id": "1504312c7a3f0a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Assign images to partitions",
   "id": "531a6eba13f8cb8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1. Location based assignment",
   "id": "7ffd3ca5b68a54f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene_config.location_based_enlarge = 0.1",
   "id": "13e18bfed06a0c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.camera_center_based_partition_assignment().sum(-1)",
   "id": "477e65f3f958f14a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2. Visibility based assignment\n",
    "\n",
    "the visibility is calculated from 3D points of every camera"
   ],
   "id": "b36dc940c0bd23f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# some parameters may need to be changed\n",
    "scene_config.visibility_based_distance = 0.9  # enlarge bounding box by `partition_size * max_visible_distance`, only those cameras inside this enlarged box will be used for visibility based assignment\n",
    "scene_config.visibility_threshold = 0.25"
   ],
   "id": "633fbba46316ae75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "define image 3D point getter",
   "id": "3a6bf655d48ade76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter out points with large errors\n",
    "min_cameras = 3\n",
    "max_errors = 2.\n",
    "\n",
    "shared_point_mask = torch.logical_and(\n",
    "    torch.ge(point_n_images, min_cameras),\n",
    "    torch.le(point_errors, max_errors),\n",
    ")\n",
    "\n",
    "shared_point_mask.sum()"
   ],
   "id": "c7bfd13af9a1430f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_image_points(image_idx: int):\n",
    "    image_key = image_idx_to_key[image_idx]\n",
    "    # get valid points\n",
    "    points_ids = torch.from_numpy(colmap_model[\"images\"][image_key].point3D_ids)\n",
    "    points_ids = points_ids[points_ids > 0]\n",
    "    \n",
    "    # filter\n",
    "    points_ids *= shared_point_mask[points_ids]\n",
    "    points_ids = points_ids[points_ids > 0]\n",
    "    \n",
    "    return reoriented_point_cloud_xyz[points_ids]"
   ],
   "id": "931cd65620d5bf47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "start calculating visibilities",
   "id": "5d59c0d68ed90886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scene.calculate_point_based_camera_visibilities(\n",
    "    point_getter=get_image_points,\n",
    "    device=reoriented_point_cloud_xyz.device,\n",
    ").shape"
   ],
   "id": "3cd812b14e3ac7d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "assign cameras to partitions based on visibilities",
   "id": "2657ad1c7d8c16d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "scene.visibility_based_partition_assignment().sum(dim=-1)",
   "id": "6955eec1079b0e7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Preview",
   "id": "5c9cbb8b3e147daf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_plot_points = 51_200\n",
    "plot_point_sparsify = max(valid_reoriented_point_xyzs.shape[0] // max_plot_points, 1)\n",
    "plot_point_sparsify"
   ],
   "id": "ed6b811a9221b0c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx in range(len(scene.partition_coordinates)):\n",
    "    scene.plot(scene.plot_partition_assigned_cameras, idx, valid_reoriented_point_xyzs, valid_point_rgbs, point_sparsify=plot_point_sparsify)"
   ],
   "id": "4641be5320187594",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Saving",
   "id": "7e994b1774ff1754"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_path = os.path.join(dataset_path, scene.build_output_dirname())\n",
    "output_path"
   ],
   "id": "7138bcd1e9ec1e4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.load(scene.save(\n",
    "    output_path,\n",
    "    extra_data={\n",
    "        \"up\": up,\n",
    "        \"rotation_transform\": rotation_transform,\n",
    "    }\n",
    "))"
   ],
   "id": "f4c4126fa8af3c30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_images_assigned_to_partitions = torch.logical_or(scene.is_camera_in_partition, scene.is_partitions_visible_to_cameras)\n",
    "is_images_assigned_to_partitions.sum(-1)"
   ],
   "id": "4e4130f935bb6196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "write image lists",
   "id": "33f935f6de383e88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "written_idx_list = []\n",
    "for partition_idx in tqdm(list(range(is_images_assigned_to_partitions.shape[0]))):\n",
    "    partition_image_indices = is_images_assigned_to_partitions[partition_idx].nonzero().squeeze(-1).tolist()\n",
    "    if len(partition_image_indices) == 0:\n",
    "        continue\n",
    "        \n",
    "    written_idx_list.append(partition_idx)\n",
    "        \n",
    "    camera_list = []\n",
    "    \n",
    "    with open(os.path.join(output_path, \"{}.txt\".format(scene.partition_coordinates.get_str_id(partition_idx))), \"w\") as f:\n",
    "        for image_index in partition_image_indices:\n",
    "            f.write(image_name_list[image_index])\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # below camera list is just for visualization, not for training, so its camera intrinsics are fixed values\n",
    "            color = [0, 0, 255]\n",
    "            if scene.is_partitions_visible_to_cameras[partition_idx][image_index]:\n",
    "                color = [255, 0, 0]\n",
    "            camera_list.append({\n",
    "                \"id\": image_index,\n",
    "                \"img_name\": image_name_list[image_index],\n",
    "                \"width\": 1920,\n",
    "                \"height\": 1080,\n",
    "                \"position\": c2w[image_index][:3, 3].numpy().tolist(),\n",
    "                \"rotation\": c2w[image_index][:3, :3].numpy().tolist(),\n",
    "                \"fx\": 1600,\n",
    "                \"fy\": 1600,\n",
    "                \"color\": color,\n",
    "            })\n",
    "            \n",
    "    with open(os.path.join(\n",
    "            output_path, \n",
    "            f\"cameras-{scene.partition_coordinates.get_str_id(partition_idx)}.json\",\n",
    "    ), \"w\") as f:\n",
    "        json.dump(camera_list, f, indent=4, ensure_ascii=False)"
   ],
   "id": "ce94d0624b099486",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_store_points = 512_000\n",
    "store_point_step = max(valid_point_rgbs.shape[0] // max_store_points, 1)\n",
    "from internal.utils.graphics_utils import store_ply\n",
    "store_ply(os.path.join(output_path, \"points.ply\"), point_xyzs[valid_point_mask][::store_point_step], valid_point_rgbs[::store_point_step])"
   ],
   "id": "e5652916f37e4e18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Run below commands to visualize the partitions in web viewer:\\n\")\n",
    "for partition_idx in written_idx_list:\n",
    "    id_str = scene.partition_coordinates.get_str_id(partition_idx)\n",
    "    print(\"python utils/show_cameras.py \\\\\\n    --cameras='{}' \\\\\\n    --points='{}'\\n\".format(\n",
    "        os.path.join(output_path, \"cameras-{}.json\".format(id_str)),\n",
    "        os.path.join(output_path, \"points.ply\"),\n",
    "    ))"
   ],
   "id": "e3f9ca368844d2fe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
